---
title             : "Predicting Red Wine Quality with Different Models"
shorttitle        : "Predicting Wine Quality"
author: 
  - name          : "Shijing Zhou"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    email         : "shijingz@uoregon.edu"
affiliation:
  - id            : "1"
    institution   : "University of Oregon"
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
library("papaja")
library(tidyverse)
library(randomForest)
library(ISLR)
library(psych)
library(corrplot)
library(rpart)
library(MASS)
library(pROC)
library(gbm)
library(finalfit)
library(tidyverse)
library(sjPlot)
library(sjstats)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Research Problem
Wine Quality Data Set is obtained from UCI [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality). The website contains two datasets, which are related to red and while wines sample from  vinho verde, which is from the north of Portugal (Cortez et al., 2009). For this project, only data on the red wine samples were used to create models. The aim of the project is to use physicochemical data of wine to predict the quality of wine. Building a model of predicting red wine quality from objective data could potentially not only help to establish wine tasting guideline from the perspective of merchants and consumers, but also help to improve wine production from the perspective of winery as the producer.

# Description of the Data

## Core features and descriptive statistics
The dataset contains a total of 12 variables. The outcome of interest is wine quality (`quality`). There are also physicochemical measures of red wine samples, including fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol. 

```{r eval=TRUE, echo=FALSE}
wine <- readr::read_csv("https://raw.githubusercontent.com/shijing-z/EDLD654-Final-Project/main/data/winequality-red.csv")
describe(wine, skew = FALSE)
```

## Missing data check
No missingness was found for the variables in the dataset. 

```{r eval=TRUE, echo=FALSE}
ff_glimpse(wine)$Continuous[,c('n','missing_percent')] 
```

## Outcome transformation
As a consumer, I may consider `quality` as a key binary outcome (i.e., good or bad) for my decision on which wine I should buy. Hence, it makes sense to transform the variable, `quality`, to a categorical variable with binary outcomes (i.e., 1 = Good, 0 = Bad).

```{r eval=TRUE, echo=TRUE}
wine$quality <- I(wine$quality > 6) * 1
```

# Description of the models
Three different modeling approaches will be used to predict quality of wine from 11 physicochemical measures of wine, including Logistic Regression, Classification Trees, and Random Forest. 
Since the aim of the project is to develop a tool that could be used by both consumers, merchants, and winery, it make sense to treat the outcome of interest, `quality`, as binary and run a logistic regression with other continuous physicochemical variables. It is always good to run a generalized linear model (GLM) as a baseline to compare with other more advanced models.
For classification tree, it is a advanced tool for outcome prediction. Also, for winery as the producer of wine, decision trees may help them to find and prioritize the most important factors for wine quality during production.
Random Forests is a even more advanced tool using bootstrap (i.e., random sample of rows in training dataset with replacement) to predict more unbiased outcomes.  
For all models, I am planning to use Area Under the Receiver Operating Curve (AUC or AUROC) and True Positive Rate (TPN) to evaluate those models. For the outcome of interest with different perspectives from winery, merchants, and consumers, it makes the most sense to see how well the model does to predict good quality wine when the wine is really good, because it is related to the profit of winery and merchants, and consumer experience experience.

# Model Fits

## Preparation
The dataset is split into training and test set with the following code. The training set has 1,000 observations, and the test set has 599 observations. I also prepared a function to easy calculate TNR for each model.

```{r eval=TRUE, echo=TRUE}
set.seed(8) 
X <- scale(wine[,1:11])
tst <- 1:599
train <- wine[-tst,]
test <- wine[tst,]

# Function to calculate True Postive Rate (TPR)
TPR <- function(y,yhat)  { sum(y==1 & yhat==1) / sum(y==1) }
```

## Model 1: Logistic Regression
The logistic regression indicated a TRP of 21.33%, and a AUC of 87.22%.

```{r eval=TRUE, echo=FALSE}
glm <- glm(quality ~ ., 
           family="binomial", 
           data=train)
test$yhat.glm <- predict(glm, test, type="response")
table(test$quality, test$yhat.glm > 0.5)
TRP_GLM <- TPR(test$quality, test$yhat.glm > 0.5)
TRP_GLM

glm.roc <- roc(test$quality, test$yhat.glm, direction="<")
glm.roc
```

## Model 2: Decision Tree 
The classification trees model after pruning indicated a TRP of 55.26%, and a AUC of 79.51%.

### Classification trees 1
A explorotory classification trees model

```{r eval=TRUE, echo=FALSE}
#Decision tree 1
form1 <- formula(quality~.)
t1 <- rpart(form1, data=train, cp= .001, method="class")
plot(t1,uniform=T,compress=T,margin=.05,branch=0.3)
text(t1, cex=.7, col="navy",use.n=TRUE)

plotcp(t1)
CP <- printcp(t1)
```

### Classification trees 2 

A new `cp` value is used in classification tree model 2 based on the classification tree model 1. The new `cp` value for the second tree model is based on the value of relative error, x error, xstd. When nsplit = 10, all error values are at their lowest.

```{r}
#Decision tree 2 based on tree 1
t2 <- prune(t1,cp = CP[6, 1])
plot(t2,uniform=T,compress=T,margin=.05,branch=0.3)
text(t2, cex=.7, col="navy",use.n=TRUE)

#calculate the yhat table and TPR
yhat.t2 <- predict(t2, test, type="prob")[,2]
table(yhat.t2>0.5, test$quality)
TPR_tree <- TPR(yhat.t2>0.5, test)
TPR_tree 

#create ROC
t2.roc <- roc(test$quality, yhat.t2, direction = "<")
t2.roc
```

## Model 3: Random Forest
The Ramdom Forest model indicated a TRP of 80%, and a AUC of 86.54%.

```{r eval=TRUE, echo=FALSE}
#set parameters
Y <- factor(train$quality)
X <- as.matrix(train[,1:11])

#set random tree
mtry <- round(ncol(X)^.5); 
ntree <- 1000
rf1 <- randomForest(x=X, y=Y, ntree=ntree, mtry=mtry, importance=TRUE)
rf1

summary(rf1)
names(rf1)

importance(rf1)

varImpPlot(rf1)

#Evaluate the predictions
pred.rf1 <- predict(rf1, test)
table(pred.rf1, test$quality)
TPR_forest <- TPR(pred.rf1, test)
TPR_forest

yhat.rf1 <- predict(rf1, test, type="prob")[,2]

rf1.roc <- roc(test$quality, yhat.rf1, direction="<")
rf1.roc
```

## Plot of Model Comparison
Based on TPR and AUC, it seems that Random Forest model did an outstanding job to predict the outcome. However, based on ROC curves (i.e., trade-off between TPR (sensitivity) and TNR (specificity)), it looks that the Random Forest model performed just slightly better than the logistic regression model, and the worst performed model seems to be classification trees (after pruning) model. Hence, I would choose Random Forest model as the optimal model to predict wine quality from from physicochemical data of wine with the comparisions and results described above.
See the following plot for model comparison.

```{r eval=TRUE, echo=FALSE}
plot(glm.roc) 
plot(t2.roc)
plot(rf1.roc)
lines(glm.roc, lwd=2, col = "green")
lines(t2.roc, lwd=2, col = "yellow")
lines(rf1.roc, lwd=2, col = "red")
legend("bottomright",
       title="ROC Curves",c("glm","tree","random forest"), 
       fill=c("green","yellow","red"))
```

# Discussion
The three different models definitely gave me different results on predicting powder depending on different method of evaluation. If I only consider TPR and AUC for my model performance, the random forest model is outstanding compared the rest of models, but the random forest model seemed to perform similarly if I also take True Negative Rate (TNR) into consideration.

In the random forest model, it looks like `alcohol` was the most important predictor for the outcome, `quality`. This is certainly surprising for me. I thought factors such as pH levels and residual sugar matter more regarding the taste. However, I realized that wine quality is not all about taste. Color, smell, how wine looks from different angles of glass, and how wine swirls in a glass also matter to wine quality. I think this is very informative, mostly for winery as the producer of wine, to focus on how alcohol plays a role in production to improve their products. 


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. Decision Support Systems, 47(4), 547â€“553. https://doi.org/10.1016/j.dss.2009.05.016

<div id="refs" custom-style="Bibliography"></div>
\endgroup
